{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "* Dropping duplicate data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in Data Analysis\n",
    "\n",
    "1. Data collecting from sources\n",
    "2. Clean through unnecessary data\n",
    "3. analyzing data/ Processing data \n",
    "\n",
    " will learn data preprocessing techniques with scikit-learn, one of the most popular frameworks used for industry data science\n",
    " The scikit-learn library includes tools for data preprocessing and data mining. It is imported in Python via the statement import sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation \n",
    "* if the dataset is missing too many values, we just don't use it\n",
    "*  if only a few of the values are missing, we can perform data imputation to substitute the missing data with some other value(s).\n",
    "* There are many different methods for data imputation\n",
    "    * Using the mean value\n",
    "    * Using the median value\n",
    "    * Using the most frequent value\n",
    "    * Filling in missing values with a constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Techniques\n",
    "* Data Preprocessing is a technique that is used to convert the raw data into a clean data set\n",
    "\n",
    "### Data preprocessing steps\n",
    "\n",
    "* loading data \n",
    "* exploring data \n",
    "* cleaning data \n",
    "* Transforming data \n",
    "\n",
    "#### Advantages\n",
    "* For achieving better results\n",
    "* Increses accuracy\n",
    "\n",
    "### Standardizing Data\n",
    "\n",
    "* Data scientists will convert the data into a standard format to make it easier to understand.\n",
    "* The standard format refers to data that has 0 mean and unit variance (i.e. standard deviation = 1), and the process of    converting data into this format is called data standardization.\n",
    "* improve the performance of models\n",
    "* it rescales the data to have mean = 0 and varience(statistical measure that provides indicator of data's dispresion) = 1\n",
    "\n",
    "* Standardization rescales data so that it has a mean of 0 and a standard deviation of 1.\n",
    "* The formula for this is:  (ùë• ‚àí ùúá)/ùúé\n",
    "\n",
    "    * We subtract the mean (ùúá) from each value (x) and then divide by the standard deviation (ùúé)\n",
    "    \n",
    "![stddata.PNG](stddata.PNG)\n",
    "\n",
    "![std.PNG](std.PNG)\n",
    "[dataset_Link]()\n",
    "\n",
    "### Data Range\n",
    "\n",
    "* Scale data by compressing it into a fixed range\n",
    "* One of the biggest use cases for this is compressing data into the range [0, 1]\n",
    "* MinMaxScaler \n",
    "![minmax.PNG](minmax.PNG)\n",
    "\n",
    "### Normalizing Data\n",
    "\n",
    "* Want to scale the individual data observations (i.e. rows)\n",
    "* Rescales the data in smaller range -1.0 to 1.0 or 0.0 to 1.0.\n",
    "* Used in classification Problems and data mining \n",
    "* when clustering data we need to apply L2 normalization to each row\n",
    "* L2 normalization applied to a particular row of a data array \n",
    "* L2 norm of a row is just the square root of the sum of squared values for the row\n",
    "\n",
    "![norm.PNG](norm.PNG)\n",
    "\n",
    "\n",
    "### Robust Scaling\n",
    "* Deal with is outliers (data point that is significantly further away from the other data points)\n",
    "* Robustly scale the data, i.e. avoid being affected by outliers\n",
    "* Scaling by using data's median and Interquartile Range (IQR)\n",
    "* Here mean affected but median remains same\n",
    "* Subtract the median from each data value then scale to the IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
